{
  "0": {
    "id": "0",
    "title": "Page not found",
    "content": "Page not foundThe page you requested could not be found. Try using the navigation or search to find what you're looking for or go to this site's home page.",
    "url": "http://localhost:4000/spincycle/404",
    "relUrl": "/404"
  },
  "1": {
    "id": "1",
    "title": "API",
    "content": "API",
    "url": "http://localhost:4000/spincycle/v1.0/api",
    "relUrl": "/v1.0/api"
  },
  "2": {
    "id": "2",
    "title": "Auth",
    "content": "AuthSpin Cycle supports role-based authentication (RBAC). As an open-source product, Spin Cycle provides the auth framework and you provide the implementation details. There are no built-in or default roles; roles are user-defined and determined during authentication. By default, auth is disabled: everyone can do everything.Auth is a whitlelist. To allow a request, callers (any HTTP client) must have a role that matches a role defined for the request. Authentication assigns roles to callers. Requests are given ACLs (access control lists) when the specs are written. Authorization matches the former (caller roles) to the latter (request ACLs). If there is a match, the request is allowed; else, the request is denied.Global admin roles can be configured. This makes it easy to ensure admins always have access, without having to define access for every request. See auth.admin_roles.Enabling auth requires writing an auth plugin and defining request ACLs.Auth PluginAn auth.Plugin is required to enable authentication. Primarily, the Authenticate method contains user-specific logic for determining the Caller and its roles.Spin Cycle does pre-authorization: before calling the Authorize method of the auth plugin, Spin Cycle matches caller roles to the request ACL. (Or, if caller has an admin role, authorization is successful regardless of request ACLs.) If there is a match, the Authorize method is called. The plugin can do further authorization based on request-specific details.Since the auth plugin is code, see Extensions for enabling the plugin and custom building Spin Cycle.Request ACLsRequest access control lists (ACLs) are defined in request specs:sequences:  restart-app:    request: true    args:      required:        - name: app          desc: &quot;App name&quot;    acl:      - role: eng        admin: true      - role: ba        ops: [&quot;start&quot;]    nodes:The request spec snippet above, for request “restart-app”, has two ACLs. The first defines that callers with the “eng” role are request admins, i.e. allowed to do anything with the request. The second defines that callers with the “ba” role can start the request. Access is denied if the caller does not have one of these two roles, or a role listed in auth.admin_roles.“ops” is currently a placeholder for future authorization. The allowed values are “start” and “stop”.Spin Cycle automatically pre-authorizes caller based on request ACLs. If allowed, it calls the Authorize method of the auth plugin which can do further authorization. For example, this request has an app arg. The auth plugin could authorize callers to restart only apps they own.",
    "url": "http://localhost:4000/spincycle/v1.0/operate/auth.html",
    "relUrl": "/v1.0/operate/auth.html"
  },
  "3": {
    "id": "3",
    "title": "Basic Concepts",
    "content": "Basic ConceptsRequests, sequences, and jobs are the building blocks of Spin Cycle:RequestA request is something users can ask Spin Cycle to do. For example, request “stop-mysql” allows users to stop MySQL. You create requests; Spin Cycle has no built-in requests. Requests are any functionality you want to expose to users. For example, the database team at Square exposes “stop-host” and “start-host” requests so that the hardware team can safely stop and start database hosts.From the user’s point of view, everything is a request. Requests can have required and optional arguments (“args”), the values of which are provided by the user. A “stop-host” request probably has a required “hostname” arg to let the user specify which host to stop. Apart from the request args, the request is a black box to the user: users don’t know (and shouldn’t know) how requests are accomplished.SequenceA sequence is a unique set of jobs. (Don’t worry what jobs are, those are explained next.) Sequences are an implementation detail of requests that users don’t see. You—a Spin Cycle operator and developer—create sequences and combine them to create requests. In the diagram above, two sequences comprise the request.Ideally, sequences are reusable, but they don’t have to be. For example, the database team at Square has a “provision-database-node” sequence which provisions a single database instance. This sequence is used by different requests. For example, it’s used by the request that provisions a new database cluster, and it’s used by the request that adds a database node to an existing cluster.JobA job is an atomic, reusable unit of work. Of the three building blocks, jobs are the most important because they do actual work. (Under the hood, requests are directed acyclic graphs, sequences are subgraphs, and jobs are vertices/nodes.) For example:  add-ip-addr: Add an IP address to a network interface  wait-port: Wait for a port to open (process listening on port)  install-pkg: Install a package (apt/yum/etc.)  create-cname-record: Create a CNAME DNS record  set-mysql-read-only: Enable MySQL read-only (disable writes)These jobs are very small and complete (atomic), very reusable, and do actual work. If they seem too small in isolation, remember: multiple jobs form sequences, and sequences can be a much larger units of work. Instead of having “big” jobs that do multiple things, write small jobs that do one thing, then combine the jobs into a sequence to logically encapsulate the bigger unit of work. For example, let’s pretend that stopping MySQL involves:  Enable read-only  Disconnect clients  Stop mysqldA single job could do all three steps, but it’s better to write three jobs—one for each step—and create a sequence called “stop-mysql” that executes the three jobs. This makes each job reusable in other sequences, and makes the sequence reusable in other requests. Also, smaller jobs are easier to understand, write, debug, and test—especially for other engineers.You will write a lot of jobs. For example, the request to provision a new database cluster at Square is over 100 jobs. Spin Cycle requires understanding and programming every step of an infrastructure task. It’s rigorous but required for platform automation at scale.Request Specs“Specs” are YAML files where you define requests, sequences, and jobs in sequences. The spec for the diagram above looks like:---sequences:  stop-host:    request: true    args:      required:        - name: hostname          desc: &quot;Hostname of machine to stop&quot;    nodes:      job-a:        category: job        type: jobs/a        args:          - expected: hostname            given: hostname        sets: [new-arg]        deps: []      job-b:        category: job        type: jobs/b        args: []          - expected: new-arg            given: new-arg        sets: []        deps: [job-a]      do-seq-2:        category: sequence        type: seq-2        args: []        deps: [job-b]Don’t worry about the details, neither the diagram nor the spec are complete, they’re only basic examples to give you an idea what sequence specs look like.Request specs are necessarily meticulous because you must specify every sequence, job, arg, and how they connect. (Under the hood, Spin Cycle creates a directed acyclic graph.) This requires upfront work, but trust us: the long-term benefits greatly exceed the short-term costs. One reason why: reusable sequences and jobs develop a flywheel effect, so new requests become quicker to create because the building blocks already exist.Sequence ExpansionSequence expansion refers to generating requests from static specs and variables args. Consider request “shutdown-host” to shutdown a physical host that runs a variable number of virtualized hosts. For example, a physical host could be running virtual host1, virtual host2, etc. We want “shutdown-host” to require only the physical hostname, automatically determine the virtual hosts on it, and shut them down in parallel. Solution:One job (not shown) takes required arg “physicalHost”, determines the virtual hosts, and sets a new arg “hosts” (list of virtual hostnames on “physicalHost”). Sequence 1 is expanded on each value in “hosts”, passing the current list element as arg “hostname” to the expanded sequence (Sequence 1-1 and Sequence 1-2). The lone job in the sequence expects args “hostname”, which it uses to stop that virtual host.Sequence 1 is statically defined in the request spec. When requested, the user arg “physicalHost” and a job (not shown) sets arg “hosts”. With sequence expansion, the static spec yields a different request based on the args.Sequence expansion is not required but it should be used. For example, instead of expanding a sequence, a job could iterate on “hosts”. Spin Cycle doesn’t prevent this, but it should be avoided unless needed. Sequence expansion has many benefits. One benefit is parallelism: expanded sequence run in parallel. Another benefit is isolation: expanded sequences execute independently, which is important for error handling, sequence retry, etc.Sequence expansion is to Spin Cycle what xargs is to the command line.Request ManagerThe Request Manager (RM) is the user-facing API. Users and clients only communicate with the RM. As its name suggests, it’s responsible for requests: generating from specs, storing in MySQL, status, logging, etc. Client authentication and authorization happens in the RM. From the user’s point of view, Spin Cycle and the Request Manager are the same.Behind the scenes, the RM is one of two APIs that comprise Spin Cycle (the Job Runner is the other). The RM has its own configuration and is a separate build and deployable.Job RunnerThe Job Runner (JR) is an API that runs jobs. Only the RM communicates with the JR. There are no user-facing JR API endpoints. After the RM generates and stores a request, it sends the request to the JR which runs the jobs. Since requests are directed acyclic graph under the hood, the JR is graph traverser. It executes jobs in the correct order and handles dependencies, retries, errors, etc. When a job completes (or is retried), the JR sends a job log entry (JLE) to the RM which stores it. When requested by a user through the RM, the JR reports the real-time job status of every job currently running. When a JR instance is stopped, it suspends running jobs and sends them back to any RM instance, which tries to resume the jobs by sending them back to any available JR instance. This is the basic functionality of Spin Cycle high availability.Job FactoryThe job factory makes jobs. Spin Cycle has no built-in jobs and doesn’t introspect or automatically discover jobs. Instead, you provide a job factory which Spin Cycle uses to make jobs specified in requests. For example, in the request spec above there is:job-a:  category: job  type: jobs/aSpin Cycle calls the job factory to make a jobs/a job. The job name is job-a (from the spec), and Spin Cycle gives the newly created job an ID that’s unique in the request. Internally, Spin Cycle uses the job ID because job type and name are not unique (a request can reuse the same job type, and sequences can reuse the same job name).Both Request Manager and Job Runner use the job factory. The RM makes jobs when generating the request, and the JR makes jobs when running the request. Don’t worry about the difference and details; it will become more clear in the development section of the docs.High-level System DiagramThe aforementioned concepts and components form Spin Cycle at a high level:There’s more to learn and do, but everything relates to the basic concepts presented here.",
    "url": "http://localhost:4000/spincycle/v1.0/learn-more/basic-concepts.html",
    "relUrl": "/v1.0/learn-more/basic-concepts.html"
  },
  "4": {
    "id": "4",
    "title": "Configure",
    "content": "ConfigureThe Request Manager (RM) and Job Runner (JR) binaries are configured with a YAML config file and environment variables. Configuration values are loaded in this order:  Built-in defaults  Config file  Environment variablesThe built-in defaults are only sufficient to run a local development instance. You can compile the binaries and run them without any options, using only the built-in default configs.For a production deploy, you must provide a YAML config file or environment variables to configure Spin Cycle to your infrastructure. These are the most important config values:            Request Manager      Job Runner                  server.addr      server.addr              jr_client.url      rm_client.url              mysql.dsn                     specs.dir             The RM and JR log the final config on startup.Config FileSpecifyingYou can specify a config file when starting the RM and JR:$ request-manager /etc/spincycle/rm-config.yamlThe RM reads /etc/spincycle/rm-config.yaml and fails to start if it does not exist or is invalid.Else, by default, the RM and JR read config/&amp;lt;ENVIRONMENT&amp;gt;.yaml if environment variable ENVIRONMENT is set and equal to “development”, “staging”, or “production”. For example:$ export ENVIRONMENT=production$ request-managerThe RM reads config/production.yaml (relative to the current working directory). Unlike an explicit config file, an implicit config file does not need to exist. If it does not exist, built-in defaults or environment values are used.FormatThe config file is YAML with multiple sections: server, mysql, specs, etc. The config package documents each section. Note: struct field and YAML field names are different. YAML field names are lower-case and snake_case. Here is a partial example:---server:  addr: 10.0.0.50:32308  tls:    cert_file: /secret/mycorp.crt    key_file:  /secret/mycorp.key    ca_file:   /secret/mycorp.camysql:  dsn: &quot;spincycle@tcp(spin-mysql.local:3306)/spincycle_production&quot;specs:  dir: /data/app/spin-rm/specs/jr_client:  url: https://spincycle-jr.mycorp.local:32307Environment VariablesMost config options have a corresponding environment variable, like SPINCYCLE_RM_CLIENT_URL for rm_client.url. Exceptions are noted.Take a config option, change . to _, upper-case everything, and add SPINCYCLE_ prefix.Request Managerauth.admin_roles: Callers with one of these roles are admins (allowed all ops) for all requests. (No environment variable.)auth.strict: Strict requires all requests to have ACLs, else callers are denied unless they have an admin role. Strict is disabled by default which, with the default auth plugin, allows all callers (no auth). (No environment variable.)jr_client.url: URL that Request Manager uses to connect to any Job Runner. If TLS enabled on JR, use “https” and configure TLS. In production, this is usually a load balancer address in front of N-many JR instances.jr_client.tls: Enable TLS when RM connects to any JR at jr_client.url. See common TLS section below.mysql.dsn: DSN specifying connection to MySQL. The DSN must specify the database, for example: /spincycle_production. Do use tls DSN parameter, specify the TLS config and Spin Cycle will add the tls DSN parameter automatically.mysql.tls: Enable TLS connection to MySQL. See common TLS section below.server.addr: Network address:port to listen on. To listen on all interfaces on the default port, specify “:32308”.server.tls: Enable TLS for clients (users) and when JR connects to RM. See common TLS section below.specs.dir: Directory containing all request spec files. Subdirectories are ignored. The default is “specs/”, relative to current working dir.Job Runnerrm_client.url: URL that Job Runner uses to connect to any Request Manager. If TLS enabled on RM, use “https” and configure TLS. In production, this is usually a load balancer address in front of N-many RM instances.rm_client.tls: Enable TLS when JR connects to any RM at rm_client.url. See common TLS section below.server.addr: Network address:port to listen on and to report to RM. This must be the address of the specific JR instance that RM can connect to. Do not use a load balancer address.server.tls: Enable TLS for incoming connections from RM. See common TLS section below.TLSSeveral sections have a TLS section: server, jr_client, rm_client, and mysql. The TLS config at each section is separate, so there are potentially four different TLS configs.To enable TLS, all three files for a section must be specified. For example, to enable mysql.tls, you must specify mysql.tls.cert_file, mysql.tls.key_file, and mysql.tls.ca_file.tls.cert_file: Certificate key filetls.key_file: Private key filetls.ca_file: Certificate Authority file",
    "url": "http://localhost:4000/spincycle/v1.0/operate/configure.html",
    "relUrl": "/v1.0/operate/configure.html"
  },
  "5": {
    "id": "5",
    "title": "Deploy",
    "content": "DeploySpin Cycle has three deployables: Request Manager API (RM), Job Runner API (JR), and spinc (CLI). The APIs can be deployed on the same machine, but it is recommended to deploy them separately. Network connectivity between APIs is required: RM connects to JR, and JR connects to RM.Both APIs are horizontally scalable: you can deploy N-many and distribute access with load balancing. The RM is completely stateless, but the JR is stateful with respect to the requests its currently running. Each RM instance must be able to connect directly and indirectly to each JR instance. JR instances report server.addr as their address, and RM connect directly to these addresses to get request status. When starting new requests, RM connect to any JR using jr_client.url. See Networking.The CLI, spinc, is deployed wherever convenient for users and can reach the RM, if network security is a concern.System Requirements  Go 1.10 or newer  MySQL 5.6 or newer  Network allowed between APIs  Network allowed from spinc to RMBuildingTo build open-source Spin Cycle, you must symlink it to your jobs repo. Presuming your jobs repo is located at $GOPATH/src/mycorp.local/spincycle/jobs/:# Change to open-source Spin Cycle repo root$ cd $GOPATH/src/github.com/square/spincycle# Remove the empty jobs repo$ rm -rf jobs/# Symlink jobs to your jobs repo$ ln -s $GOPATH/src/mycorp.local/spincycle/jobs/# Verify that jobs in open-source report points to your jobs repo$ ls -l jobslrwxr-xr-x  1 user user  62 Feb 24 10:47 jobs -&amp;gt; /go/src/mycorp.local/spincycle/jobs/Now when you compile Spin Cycle, it will compile in your jobs repo. To compile each deployable:$ cd request-manager/bin/$ go build -o request-manager$ cd ../../job-runner/bin/$ go build -o job-runner$ cd ../../spinc/bin/$ go build -o spincOf course, you will probably script this build process in a CI system.Building with extensions requires a different process.DeployingSpin Cycle has no specific deployment requirements, other than being configured correctly. Simply run the compiled binaries, provide a config file or environment variables, and—for the Request Manager—provide the specs dir. For example, we use a Docker container with a simple layout:$ ls /app/request-managerbin/  request-managerspecs/  &amp;lt;spec files&amp;gt;.yamlconfig/  production.yamlThen run bin/request-manager from the root dir (/app/request-manager) and it will default to reading config/produciton.yaml (if environment varaible ENVIRONMENT=production) and read specs from specs/. The Job Runner is deployed the same, minus the specs.MySQLBe sure to create the MySQL database and schemas. The database is configured in the DSN: mysql.dsn. We suggest spincycle_production for production.Also create the MySQL user, which is also configured in the DSN: mysql.dsn. The user needs all privileges on the database.",
    "url": "http://localhost:4000/spincycle/v1.0/operate/deploy.html",
    "relUrl": "/v1.0/operate/deploy.html"
  },
  "6": {
    "id": "6",
    "title": "Dev Env",
    "content": "Development EnvironmentRun docker-compose up in the repo root directory to run Spin Cycle locally using the jobs and specs in dev/. Then compile spinc:~/Development/go/src/github.com/square/spincycle/spinc/bin$ go build -o spinc~/Development/go/src/github.com/square/spincycle/spinc/bin$ ./spincRequest Manager address: http://127.0.0.1:32308Requests:  testspinc help  &amp;lt;request&amp;gt;spinc start &amp;lt;request&amp;gt;The first line indicates that spinc is querying Spin Cycle locally.Ideally, production could be simulated locally, allowing you to develop and test real Spin Cycle requests on your laptop. But in reality, this is rarely possible. The development environment is a laboratory for experimenting with and learning about Spin Cycle, and “lab work” usually needs to be adapted for production use.RebuildDocker containers, once built, are static. If you change files in dev/, you must docker-compose build to rebuild the containers, which copies dev/.",
    "url": "http://localhost:4000/spincycle/v1.0/develop/dev-env.html",
    "relUrl": "/v1.0/develop/dev-env.html"
  },
  "7": {
    "id": "7",
    "title": "Develop",
    "content": "Develop",
    "url": "http://localhost:4000/spincycle/v1.0/develop",
    "relUrl": "/v1.0/develop"
  },
  "8": {
    "id": "8",
    "title": "Endpoints",
    "content": "Endpoints  Requests          Create and start a new request      Get a request      Stop a request      Get all job logs for a request      Get logs for a specific job in a request      Get status of all running jobs and requests      Find requests that match certain conditions.      Get list of all available requests      RequestsAll things related to Spin Cycle requests.Create and start a new request  POST  /api/v1/requests  Request Parameters                    Parameter        Type        Description                            type        string        The type of request to create                    args        object        The arguments for the request              Sample Request Body  {  &quot;type&quot;: &quot;test&quot;,  &quot;args&quot;: {    &quot;sleepTime&quot;: &quot;1000&quot;  }}    Sample Response  {  &quot;id&quot;: &quot;bafebl1ddiob71ka5bag&quot;,  &quot;type&quot;: &quot;test&quot;,  &quot;state&quot;: 1  &quot;user&quot;: &quot;kristen&quot;,  &quot;args&quot;: {    &quot;sleepTime&quot;: &quot;1000&quot;  },  &quot;createdAt&quot;: &quot;2019-03-15T16:49:59Z&quot;,  &quot;startedAt&quot;: &quot;2019-03-15T16:49:59Z&quot;,  &quot;finishedAt&quot;: &quot;2019-03-15T16:55:42Z&quot;,  &quot;totalJobs&quot;: 2,  &quot;finishedJobs&quot;: 0}    Response Status Codes  201: Successful operation.  400: Invalid request. Either the request type does not exist, or the args are invalid.  401: Unauthorized operation.  503: The Request Manager (RM) API server is in the process of shutting down.Get a request  GET  /api/v1/requests/${requestId}  Sample Response  {  &quot;id&quot;: &quot;bihqongkp0sg00cq9vo0&quot;,  &quot;type&quot;: &quot;test&quot;,  &quot;state&quot;: 3,  &quot;user&quot;: &quot;kristen&quot;,  &quot;args&quot;: [    {      &quot;Pos&quot;: 0,      &quot;Name&quot;: &quot;sleepTime&quot;,      &quot;Desc&quot;: &quot;How long to sleep (milliseconds) during the request. Useful to verify how RM and JR respond before request has finished.&quot;,      &quot;Type&quot;: &quot;optional&quot;,      &quot;Given&quot;: true,      &quot;Default&quot;: &quot;1000&quot;,      &quot;Value&quot;: &quot;1000&quot;    }  ],  &quot;createdAt&quot;: &quot;2019-04-02T18:39:26Z&quot;,  &quot;startedAt&quot;: &quot;2019-04-02T18:39:26Z&quot;,  &quot;finishedAt&quot;: &quot;2019-04-02T18:39:27Z&quot;,  &quot;JobChain&quot;: {    &quot;requestId&quot;: &quot;bihqongkp0sg00cq9vo0&quot;,    &quot;jobs&quot;: {      &quot;3RNT&quot;: {        &quot;id&quot;: &quot;3RNT&quot;,        &quot;name&quot;: &quot;wait&quot;,        &quot;type&quot;: &quot;sleep&quot;,        &quot;bytes&quot;: &quot;eyJkdXJhdGlvbiI6MTAwMDAwMDAwMH0=&quot;,        &quot;state&quot;: 1,        &quot;args&quot;: {          &quot;duration&quot;: &quot;1000&quot;        },        &quot;retry&quot;: 0,        &quot;sequenceId&quot;: &quot;FDbP&quot;,        &quot;sequenceRetry&quot;: 0      },      &quot;eSTn&quot;: {        &quot;id&quot;: &quot;eSTn&quot;,        &quot;name&quot;: &quot;wait&quot;,        &quot;type&quot;: &quot;sleep&quot;,        &quot;bytes&quot;: &quot;eyJkdXJhdGlvbiI6MTAwMDAwMDAwMH0=&quot;,        &quot;state&quot;: 1,        &quot;args&quot;: {          &quot;duration&quot;: &quot;1000&quot;        },        &quot;retry&quot;: 0,        &quot;sequenceId&quot;: &quot;cDNR&quot;,        &quot;sequenceRetry&quot;: 0      }    },    &quot;adjacencyList&quot;: {      &quot;3RNT&quot;: [        &quot;eSTn&quot;      ]    }  },  &quot;totalJobs&quot;: 2,  &quot;finishedJobs&quot;: 2}    Response Status Codes  200: Successful operation.  401: Unauthorized operation.  404: Request not found.Stop a request  PUT  /api/v1/requests/${requestId}/stop  Response Status Codes  200: Successful operation.  401: Unauthorized operation.  404: Request not found.Get all job logs for a request  GET  /api/v1/requests/${requestId}/log  Sample Response  [  {    &quot;requestId&quot;: &quot;bihqongkp0sg00cq9vo0&quot;,    &quot;jobId&quot;: &quot;3RNT&quot;,    &quot;try&quot;: 1,    &quot;name&quot;: &quot;wait&quot;,    &quot;type&quot;: &quot;sleep&quot;,    &quot;startedAt&quot;: 1554230366094196500,    &quot;finishedAt&quot;: 1554230367094791700,    &quot;state&quot;: 3,    &quot;exit&quot;: 0,    &quot;error&quot;: &quot;&quot;,    &quot;stdout&quot;: &quot;&quot;,    &quot;stderr&quot;: &quot;&quot;  },  {    &quot;requestId&quot;: &quot;bihqongkp0sg00cq9vo0&quot;,    &quot;jobId&quot;: &quot;eSTn&quot;,    &quot;try&quot;: 1,    &quot;name&quot;: &quot;wait&quot;,    &quot;type&quot;: &quot;sleep&quot;,    &quot;startedAt&quot;: 1554230366095376600,    &quot;finishedAt&quot;: 1554230367096359700,    &quot;state&quot;: 3,    &quot;exit&quot;: 0,    &quot;error&quot;: &quot;&quot;,    &quot;stdout&quot;: &quot;&quot;,    &quot;stderr&quot;: &quot;&quot;  }]    Response Status Codes  200: Successful operation.  401: Unauthorized operation.  404: Request not found.Get logs for a specific job in a request  GET  /api/v1/requests/${requestId}/log/${jobId}  Sample Response  {  &quot;requestId&quot;: &quot;bihqongkp0sg00cq9vo0&quot;,  &quot;jobId&quot;: &quot;3RNT&quot;,  &quot;try&quot;: 1,  &quot;name&quot;: &quot;wait&quot;,  &quot;type&quot;: &quot;sleep&quot;,  &quot;startedAt&quot;: 1554230366094196500,  &quot;finishedAt&quot;: 1554230367094791700,  &quot;state&quot;: 3,  &quot;exit&quot;: 0,  &quot;error&quot;: &quot;&quot;,  &quot;stdout&quot;: &quot;&quot;,  &quot;stderr&quot;: &quot;&quot;}    Response Status Codes  200: Successful operation.  401: Unauthorized operation.  404: Request or job not found.Get status of all running jobs and requests  GET  /api/v1/status/running  Sample Response  {  &quot;jobs&quot;: [    {      &quot;requestId&quot;: &quot;bihr0sgkp0sg00cq9vog&quot;,      &quot;jobId&quot;: &quot;96i7&quot;,      &quot;type&quot;: &quot;sleep&quot;,      &quot;name&quot;: &quot;wait&quot;,      &quot;startedAt&quot;: 1554231410126312200,      &quot;state&quot;: 2,      &quot;status&quot;: &quot;sleeping&quot;,      &quot;try&quot;: 1    },    {      &quot;requestId&quot;: &quot;bihr0tgkp0sg00cq9vp0&quot;,      &quot;jobId&quot;: &quot;4avk&quot;,      &quot;type&quot;: &quot;sleep&quot;,      &quot;name&quot;: &quot;wait&quot;,      &quot;startedAt&quot;: 1554231414572741000,      &quot;state&quot;: 2,      &quot;status&quot;: &quot;sleeping&quot;,      &quot;try&quot;: 1    }  ],  &quot;requests&quot;: {    &quot;bihr0sgkp0sg00cq9vog&quot;: {      &quot;id&quot;: &quot;bihr0sgkp0sg00cq9vog&quot;,      &quot;type&quot;: &quot;test&quot;,      &quot;state&quot;: 2,      &quot;user&quot;: &quot;&quot;,      &quot;createdAt&quot;: &quot;2019-04-02T18:56:50Z&quot;,      &quot;startedAt&quot;: &quot;2019-04-02T18:56:50Z&quot;,      &quot;finishedAt&quot;: null,      &quot;totalJobs&quot;: 2,      &quot;finishedJobs&quot;: 0    },    &quot;bihr0tgkp0sg00cq9vp0&quot;: {      &quot;id&quot;: &quot;bihr0tgkp0sg00cq9vp0&quot;,      &quot;type&quot;: &quot;test&quot;,      &quot;state&quot;: 2,      &quot;user&quot;: &quot;&quot;,      &quot;createdAt&quot;: &quot;2019-04-02T18:56:55Z&quot;,      &quot;startedAt&quot;: &quot;2019-04-02T18:56:55Z&quot;,      &quot;finishedAt&quot;: null,      &quot;totalJobs&quot;: 2,      &quot;finishedJobs&quot;: 0    }  }}    Response Status Codes  200: Successful operation.  401: Unauthorized operation.Find requests that match certain conditions.  GET  /api/v1/requests  Requests are returned in reverse chronological order by create time.  Optional Query Parameters                    Parameter        Description        Notes                            type        The type of request                             requestor        The user who created the request                             state        The state of the request        See proto.go. Specify this parameter multiple times to search for multiple states.                    since        Return only requests which were running after this time        Format: “2006-01-02T15:04:05.999Z07:00”                    until        Return only requests which were running before this time        Format: “2006-01-02T15:04:05.999Z07:00”                    limit        Maximum number of requests to return                             offset        Skip this number of requests        Use with limit for pagination of results.              Sample Response  [  {    &quot;id&quot;: &quot;bihr0sgkp0sg00cq9vog&quot;,    &quot;type&quot;: &quot;test&quot;,    &quot;state&quot;: 2,    &quot;user&quot;: &quot;Bob&quot;,    &quot;createdAt&quot;: &quot;2019-04-02T18:56:50Z&quot;,    &quot;startedAt&quot;: &quot;2019-04-02T18:56:50Z&quot;,    &quot;finishedAt&quot;: null,    &quot;totalJobs&quot;: 2,    &quot;finishedJobs&quot;: 0  },  {    &quot;id&quot;: &quot;bihr0tgkp0sg00cq9vp0&quot;,    &quot;type&quot;: &quot;test&quot;,    &quot;state&quot;: 3,    &quot;user&quot;: &quot;Alice&quot;,    &quot;createdAt&quot;:  &quot;2019-04-02T18:56:55Z&quot;,    &quot;startedAt&quot;:  &quot;2019-04-02T18:56:55Z&quot;,    &quot;finishedAt&quot;: &quot;2019-04-02T18:57:55Z&quot;,    &quot;totalJobs&quot;: 2,    &quot;finishedJobs&quot;: 2  }]    Response Status Codes  200: Successful operation.  400: Invalid parameters.  401: Unauthorized operation.Get list of all available requests  GET  /api/v1/request-list  Sample Response  [  {    &quot;Name&quot;: &quot;test&quot;,    &quot;Args&quot;: [      {        &quot;Pos&quot;: 0,        &quot;Name&quot;: &quot;sleepTime&quot;,        &quot;Desc&quot;: &quot;How long to sleep (milliseconds) during the request. Useful to verify how RM and JR respond before request has finished.&quot;,        &quot;Type&quot;: &quot;optional&quot;,        &quot;Given&quot;: false,        &quot;Default&quot;: &quot;1000&quot;,        &quot;Value&quot;: null      }    ]  }]    Response Status Codes  200: Successful operation.  401: Unauthorized operation.",
    "url": "http://localhost:4000/spincycle/v1.0/api/endpoints.html",
    "relUrl": "/v1.0/api/endpoints.html"
  },
  "9": {
    "id": "9",
    "title": "Extensions",
    "content": "ExtensionsExtensions are user-provided plugins, hooks, and factories. Extensions allow you to extend and modify how core parts of Spin Cycle work without changing the core code. As an open source project, Spin Cycle cannot include all possible solutions out of the box. Auth, for example, is user-specific. The auth plugin lets you tailor Spin Cycle auth for your security.The app packages  define and document all the extensions:  request-manager/app  job-runner/app  spinc/appStart SequenceUsing any extension requires a custom build of Spin Cycle, which is described in the next section. But first, it is helpful to understand how Spin Cycle is started because after defining your extensions, your code needs to start Spin Cycle. The default start sequences are request-manager/bin/main.go and job-runner/bin/main.go. The start sequence  is five steps which must be performed in order.1. App contextThe first step is creating an app context: app.Defaults(). This returns a default app context with default, built-in functions for all extensions. For example, the default auth plugin allows all callers. You should always begin with the defaults. Since main.go does not modify anything, the app context is not assigned to a variable. However, to define extensions, assign the app context to a variable: appCtx := app.Defaults().2. Define extensionsExtensions are defined in the app context, like:type authPlugin struct{}appCtx.Plugins.Auth = authPlugin{}That defines an authPlugin{} object as the auth plugin, presuming it implements auth.Plugin.3. Create serverCreate a new server object with the app context: s := server.NewServer(appCtx). This will be either a request-manager/server or job-runner/server.4. Boot serverBoot the server: err := s.Boot(). Booting makes the server (RM or JR) ready to run. This is when most validation happens. Error are fatal; do not run the server on error.5. Run serverThe final step is running the server: s.Run(true). This blocks until the server is stopped. After calling Run(), the API is listening on the configured address.BuildingSince extensions require defining custom values in the app context (step 2), your code must import open-source Spin Cycle. Then you build your code, which builds Spin Cycle indirectly. Furthermore, if you extend and custom build one part of Spin Cycle, you should custom build the other parts. For example, if you define an auth plugin for the Request Manager, you should also custom build the Job Runner and spinc to ensure all parts originate from the same code base.If your repo is mycorp.local/spincycle, it would contain:job-runner/  main.gojobs/  &amp;lt;jobs repo&amp;gt;request-manager/  main.gospinc/  main.govendor/  github.com/    square/      spincycle/        ...Open-source Spin Cycle is a vendor package: vendor/github.com/square/spincycle. The main.go files contain your extensions, and you build the binaries from these instead of the open-source files.Like a normal build, your jobs/ repo is needed, but the symlink is different:$ rm -f vendor/github.com/square/spincycle/jobs$ ln -s $PWD/jobs vendor/github.com/square/spincycle/jobsThe jobs/ dir in the open-source vendor copy needs to be a symlink that points to the jobs/ dir in your repo.When you update the Spin Cycle vendor dep (vendor/github.com/square/spincycle), be sure to re-link the jobs directory to your jobs repo.",
    "url": "http://localhost:4000/spincycle/v1.0/develop/extensions.html",
    "relUrl": "/v1.0/develop/extensions.html"
  },
  "10": {
    "id": "10",
    "title": "Release Notes",
    "content": "Release Notesv1.0v1.0.0 (released 2019-04-09)  First GA, production-ready release.",
    "url": "http://localhost:4000/spincycle/release-notes",
    "relUrl": "/release-notes"
  },
  "11": {
    "id": "11",
    "title": "Home",
    "content": "Spin Cycle automates and exposes complex infrastructure tasks to other teams and services. This allows a few engineers to quickly and reliably manage thousands of resources—platform automation at scale.Spin Cycle was purpose-built for platform automation at scale:  Fully REST API-driven  Highly available and horizontally scalable  Real-time status (no dark corners)  Extensive code reuse (flywheel effect)  Pluggable role-based authenticationSpin Cycle can do anything you can program. The database team at Square uses it to provision and decommission databases, safely stop and start hosts, upgrade MySQL and Docker images, reconfigure services, and more.Learn More  Basic Concepts ✨  Jobs Repo  Networking  SupportOperate  Deploy  Configure  spinc (CLI)  AuthDevelop  Dev Env  Jobs  Requests  ExtensionsAPI  Overview  EndpointsRelease Notes  Release Notes",
    "url": "http://localhost:4000/spincycle/",
    "relUrl": "/"
  },
  "12": {
    "id": "12",
    "title": "Jobs Repo",
    "content": "Jobs RepoThe jobs repo is a Go package called jobs that contains your jobs and a factory for making them. When building Spin Cycle, the open-source code is “linked” to your jobs repo. (See Building.) There are four requirements for your jobs repo:  Package name jobs  Defines package variable var Factory job.Factory  Factory implements job.Factory  Every job implements job.JobOpen-source Spin Cycle only uses the jobs.Factory package variable. In request specs, jobs are given any type name you choose. Spin Cycle makes jobs by type, by calling Factory.Make. Spin Cycle has no specific knowledge about any job. To Spin Cycle, every job is equal.You can organize the jobs repo any way you want. For example:# mycorp.local/spincycle/jobs:factory.gomysql/  start.go  stop.goredis/  start.go  stop.goThe repo root is mycorp.local/spincycle with a jobs/ package (requirement 1). The factory is implemented in jobs (requirement 2). Jobs in the jobs package are organized by database type: mysql/ and redis/. Each has two jobs: start and stop. All jobs could be in the jobs package, too, or in one db/ package, but we chose to organize them by database type.factory.go looks like:package jobsimport (    &quot;fmt&quot;    &quot;github.com/square/spincycle/job&quot;    &quot;mycorp.local/spincycle/jobs/mysql&quot;    &quot;mycorp.local/spincycle/jobs/redis&quot;)var Factory job.Factoryfunc init() {    Factory = &amp;amp;factory{}}type factory struct{}func (f factory) Make(id Id) (Job, error) {    switch id.Type {    case &quot;mysql/start&quot;:        return mysql.NewStart(), nil    case &quot;mysql/stop&quot;:        return mysql.NewStop(), nil    case &quot;redis/start&quot;:        return redis.NewStart(), nil    case &quot;redis/stop&quot;:        return redis.NewStop(), nil    }    return nil, fmt.Errorf(&quot;unknown job type: %s&quot;, id.Type)}A real factory is much more complicated, but the basic idea is the same. Private type factory implements job.Factory: func (f factory) Make(id Id) (Job, error) (requirement 3).The case statements implicitly define the job types. Specifying “mysql/start” in a request spec will match the first case, etc. You can name jobs types however you like. “mysql/start” could be called “mysql-start”, “start_MySQL”, etc. as long as it matches usage in request specs. We chose to name them matching the package organization.",
    "url": "http://localhost:4000/spincycle/v1.0/learn-more/jobs-repo.html",
    "relUrl": "/v1.0/learn-more/jobs-repo.html"
  },
  "13": {
    "id": "13",
    "title": "Jobs",
    "content": "JobsA job is an atomic, reusable unit of work. Under the hood, requests are directed acyclic graphs with jobs as the vertices. Ideally, every job in a request is a single step or task to accomplish the request. Outside a request, the best jobs are generic and reusable. For example, a job that adds a virtual IP address to a network interface is generic and reusable in many different requests. Inevitably, however, some jobs will be specific and used in only a single requests. The main goal is that one job does one thing. More reusable jobs makes your jobs repo more values, and new requests faster to create.Every job must implement the job.Job interface. Spin Cycle only uses this interface, so it has zero knowledge of job implementation details.Life CycleIt is critical to understand the life cycle of a job in a request because it affects how jobs must be written, depending on what the job does. The life cycle has two major and separate phases: create and run. These happen in the Request Manager (RM) and Job Runner (JR), respectively. In each phase is two stages.Create1. CreateJobs are first created when a request is being created by the RM. As the RM processes the request spec, it instantiates jobs by calling the Make method on the jobs.Factory from your jobs repo to create each job. Jobs should not do any work, logic, etc. when instantiated. Simply create the new job object and return.After instantiating the job object, the RM calls its Create method. This is when and where jobs should do work, logic, etc. Which work depends on the jobs because, at this point, the job is only being created, not ran. The Create method is used to “set the stage”. For example, a job might query other APIs or a database to ascertain the state of world and set some job args (described later) which influence the creation of other jobs.2. SerializeSince only the Job Runner runs jobs, after Create the RM calls the Serialize method. The job should serialize itself into a []byte which is transmitted to the JR.Serialize only data necessary and sufficient to run later. Do not serialize what can be recreated later. An internal *sync.Mutex is an example: do not serialize it, recreate it later.Run3. DeserializeWhen the JR receives a request from the RM to run, it first deserializes jobs by calling the Deserialize method. (Technically, before this it instantiates the job again by calling jobs.Factory.Make.) The job should deserialize itself and initialize any internal, private variables. For example, a job might initialize a new *sync.Mutex.The job should not do any work or logic (other than deserialization work and logic) in Deserialize.4. RunThe final stage in the life of a job is when the JR calls its Run method. As the name implies, this when the job officially runs. However, depending on what the job does, it might not have done everything in Create. That is ok. Later, we discuss create-only vs. run-only jobs. Normally, though, a job does all its “heavy lifting” in Run. For example, job “add-ip” would run sudo /sbin/ip addr add &quot;$IP/32&quot; dev &quot;$IFACE&quot; to add the IP to the network interface. Jobs can be very short or very long-running (hour and days).The job returns a job.Return which is important: if State != proto.STATE_COMPLETE (see proto.go), the JR runner might stop running the whole request. If the job or sequence is configured with retries, the JR will retry, else it will fail the whole request. A complete (successful) job allows the JR to run the next jobs, or wait for other jobs to complete to satisfy dependencies in the graph describing the request.When a job is done, the JR sends a job log entry (JLE) to the RM which stores in it MySQL. Use spinc log to see the job log.Job Args and DataJobs are created with job args: Create(jobArgs map[string]interface{}) error. Job args are initialized from request args: the required and optional arguments listed in the request spec, the values of which are provided by the caller when starting the request. Jobs use, set, and modify job args when created in the RM. Job args, like normal function arguments, help determine what a job does. For example, job “shutdown-host” could required job arg “hostname” which determines which host to shut down. That job arg could originate from a request arg (i.e. caller specifies hostname=…) or be determined and set by an earlier job. Either way, job args are used only at creation in the RM, and they form an immutable snapshot of work: request args + job args + jobs = everything the request will do or did do.This is an important concept: creating a request yields an immutable snapshot of all work.Job args, although changing during creation, are ultimately static once the request is created. Everything is stored (by the RM in its MySQL instance) so that we can always look back at any request and see what it worked on. By contrast, if an immutable record was not kept and args were only determined at runtime, we would need to rely on logs to determine which hosts the “shutdown-host” shut down, for example. Instead, this information is recorded with the request in the final job args (and also logged).Occasionally, there is a need for run-time data: Run(jobData map[string]interface{}) (Return, error). Job data is obtained only at runtime when the JR runs the job. The canonical example is MySQL replication coordinates (a binary log file name and byte offset in that file). Replication coordinates cannot be obtained at creation because they are always changing. To use repl coordinates, you must obtain them at the moment they are used.Job args are almost always the correct choice. You only need to use job data if the information must be obtained when it is used. Else, use job args to ensure that Spin Cycle can record a complete, immutable snapshot of all work it will (or did) do for the request.Job PatternsEvery job must implement the job.Job interface, but some jobs really only need the Create or Run methods to do all work. This is normal and produces two common “job patterns”.Create-only JobCreate-only jobs do all their work in the Create method. Usually, they set new job args that subsequent jobs require. For example, let’s say request “stop-container” stops a Docker container. Since that container runs on a physical host, the request needs to know the host. There are two ways to solve this:  Make the physical hostname a request arg  Make a job to determine the physical hostnameOption 1 makes the caller do all the work by providing all the inputs: container hostname and physical host hostname. But option 2 is better because the purpose of Spin Cycle is automation, so make the caller do the least amount of work and automate the rest. A job, let’s call it “host-of-container”, would require job arg “container-hostname” and from this determine and set job arg “host-hostname”. All work would be done in the Create method, and the other methods would be stubs:func (j hostOfContainer) Create(jobArgs map[string]interface{}) error {    v, ok := jobArgs[&quot;container-hostname&quot;]    if !ok {        fmt.Errorf(&quot;container-hostname job arg not set&quot;)    }    containerHostname, ok := v.(string)    if !ok {        fmt.Errorf(&quot;container-hostname job arg value is not a string&quot;)    }    // Using containerHostname, determine...    physicalHost := ...    // Save physical host hostname in job args, used by other jobs    jobArgs[&quot;host-hostname&quot;] = physicalHost    return nil}func (j hostOfContainer) Serialize() ([]byte, error) {    return nil, err // do nothing}func (j hostOfContainer) Deserialize([]byte) error {    return nil // do nothing}func (j hostOfContainer) Run(jobData map[string]interface{}) (Return, error) {    return proto.Return{State: proto.STATE_COMPLETE}, nil // do nothing}Even though the job does nothing in Run, it must return proto.Return{State: proto.STATE_COMPLETE}.Run-only JobRun-only jobs are the reciprocal of create-only jobs: all work is done in the Run method, and the other methods are stubs. Usually, a run-only job has to serialize some job args to know how to run later. Extending the previous example of request “stop-container”, another job would actually stop the container. Let’s call that job “stop-container”. It requires two job args: “container-hostname” (provided by caller as a request arg) and “host-hostname” (set by “host-of-container” job):type StopContainer struct {    ContainerHostname string    HostHostname      string}func (j *stopContainer) Create(jobArgs map[string]interface{}) error {    // Validation and type casting not shown    j.ContainerHostname = jobArgs[&quot;container-hostname&quot;]    j.HostHostname = jobArgs[&quot;host-hostname&quot;]    return nil}func (j *stopContainer) Serialize() ([]byte, error) {    return json.Marshal(j)}func (j *stopContainer) Deserialize(bytes []byte) error {    return json.Unmarshal(bytes, j)}func (j *stopContainer) Run(jobData map[string]interface{}) (Return, error) {    // Stop j.ContainerHostname on j.HostHostname    // ...    return proto.Return{State: proto.STATE_COMPLETE}, nil // do nothing}Granted, the other methods are not pure stubs, but they do no work or logic. Create only saves the two job args that Run will need. Saving these as public (exported) fields in the job structure is a quick trick for handling Serialize and Deserialize: package encoding/json only works on public fields, so this serializes only the job args and deserializes them back into place. Run does all the work.",
    "url": "http://localhost:4000/spincycle/v1.0/develop/jobs.html",
    "relUrl": "/v1.0/develop/jobs.html"
  },
  "14": {
    "id": "14",
    "title": "Learn More",
    "content": "Learn More",
    "url": "http://localhost:4000/spincycle/v1.0/learn_more",
    "relUrl": "/v1.0/learn_more"
  },
  "15": {
    "id": "15",
    "title": "Networking",
    "content": "NetworkingThe top diagram shows the simplest case: a single Request Manager (RM) API communicates with a single Job Runner (JR) API. Users, through the spinc CLI, only communicate with the RM, which communicates with the JR on their behalf.Dotted lines indicate non-specific connections. Generally, a user does not use a specific Request Manager instance. When a request is started, the RM sends it to any JR to run it.Solid lines indicate specific connections. When a user wants the status of a request, the RM connects directly to the JR running the request.The bottom diagram is a typical production deployment: N-many RM and N-many JR, both behind load balancers. Users communicate with any RM, and the RM run requests on any JR via load balancing. The RM still communicate directly with specific JR to get request status (solid line).JR instances report server.addr as their address.TLS is supported for all connectinos.",
    "url": "http://localhost:4000/spincycle/v1.0/learn-more/networking.html",
    "relUrl": "/v1.0/learn-more/networking.html"
  },
  "16": {
    "id": "16",
    "title": "Operate",
    "content": "Operate",
    "url": "http://localhost:4000/spincycle/v1.0/operate",
    "relUrl": "/v1.0/operate"
  },
  "17": {
    "id": "17",
    "title": "Overview",
    "content": "Overview  Auth  ExamplesThe Request Manager (RM) is the user-facing API of Spin Cycle. It exposes a standard JSON REST API to clients.AuthBy default, the Spin Cycle API does not require any form of authentication or authorization. If you would like to require these, please review the Auth section for more details.Examples  Create a new request    $&amp;gt; curl     -H &quot;Content-Type: application/json&quot;     -X POST -d '{&quot;type&quot;:&quot;test&quot;,&quot;args&quot;:{&quot;sleepTime&quot;:&quot;1000&quot;}}'     ${rm-url}/api/v1/requests        Get a request    $&amp;gt; curl     -H &quot;Content-Type: application/json&quot;     ${rm-url}/api/v1/requests/abcd1234      ",
    "url": "http://localhost:4000/spincycle/v1.0/api/overview.html",
    "relUrl": "/v1.0/api/overview.html"
  },
  "18": {
    "id": "18",
    "title": "Requests",
    "content": "RequestsRequests are specified in YAML files. On startup, the Request Manager (RM) reads all specs: all the .yaml files in specs.dir. Subdirectories are not currently supported, so be sure to combine all specs in one directory.All spec files have the same syntax. The RM combines specs from multiple files to complete a request. One sequence per file and descriptively named files help keep all the specs oranized and easy to find by humans.Sequence SpecThe root of every spec file is a sequence spec:---sequences:  stop-container:    request: true    args:      required:        - name: containerName          desc: &quot;Container name to stop&quot;      optional:        - name: restart          desc: &quot;Restart the container if  &quot;yes &quot;&quot;          default: &quot;&quot;      static:        - name: slackChan          default: &quot;#dba&quot;    acl:      - role: eng        ops: admin      - role: ba        ops: [&quot;start&quot;,&quot;stop&quot;]    nodes:      NODE_SPECSThis defines one or more sequences under sequences:. Although multiple sequence can be defined in a single file, we suggest one sequence per file.The example above defines one sequence called “stop-container”. (We would name this file stop-container.yaml.) If request: true, the sequence is a request that callers can make. This also makes spinc (ran without any command line options) list the request. Set request: true only for top-level sequences that you want to expose to users as requests. All requests are sequences, but not all sequences are requests. To distinguish:  request: a sequence with request: true  non-request sequence (NRS): a sequence with request: false (usually omitted)  sequence: any and all sequences, generally speakingargs:Sequences have three types of arguments (args): required, optional, and static.  required: args are, unsurprisingly, required. For requests, required args are provided by the caller, so they should be kept to a minimum—require the user to provide only what is necessary and sufficient to start the request, then figure out other args in jobs. For non-request sequences (NRS), required args are provided by the parent node (nodes are discussed in the next section).  optional: args are optional. If not explicitly given, the default value in the spec is used. In the example above, arg “restart” defaults to an empty string unless the user provides a value.  static: args are fixed values. Static arg “slackChan” has value “#dba”. Static args are useful when the value is known but differs in different sequences. For example, another request might set slackChan=#yourTeam to get Slack notifications at #yourTeam instead of #dba. This could also be solved by making slackChan a required or optional arg.In job args, there are no distinctions. jobArgs[&quot;slackChan&quot;] is the same as jobArgs[&quot;containerName&quot;], and jobs can change its value.Node SpecsA sequence is one or more node (vertex in the graph) defined under nodes:. There are three types of node specs. Shared fields (e.g. retry:) are only described once.Job NodeA job node specifies a job to run. (If this was a tree data structure, these would be leaf nodes.) Every sequence eventually leads to job nodes. This is where work happens:      expand-cluster:        category: job        type: etre/expand-cluster        args:          - expected: cluster            given: cluster        sets:          - app   # string          - env   # string          - nodes # []string        retry: 2        retryWait: 3s        deps: []All node specs begin with a node name: “expand-cluster”, in this case. Node names must be unique within the sequence. (Spin Cycle makes nodes unique within a request by assigning them an internal job ID.) category: job makes this node a job node. type: specifies the job type: “etre/expand-cluster”. The jobs.Factory in your jobs repo must be able to make a job of this type.args: lists all job args that the job requires. expected: is the job arg name that the job expects, and given: is the job arg name in the specs to use. In other words,  jobArgs[expected] = jobArgs[given]. This is useful because it is nearly impossible to make all job args in specs match all job args in jobs. For example, a spec might use “host” for a server’s hostname, but a job uses “hostname”. In this case,- expected: hostname  given: hostmakes Spin Cycle do jobArgs[&quot;hostname&quot;] = jobArgs[&quot;host&quot;] before passing jobArgs to the job.If expected == given, both must still be specified.Only job args listed under args: are passed to the job. If a job needs arg “foo” but “foo” is not listed, then jobArgs[&quot;foo&quot;] will be nil in the job. This requirement is strict and somewhat tedious, but it makes specs complete self-describing and easy to follow because there are no “hidden” args.If a job has optional args, they must be listed so they are passed to the job, in case they exist. The job is responsible for using the optional args or not. (Note: “optional” here is not the same as sequence-level optional args.)sets: specifies the job args that the job sets. The RM checks this. In the example above, the job sets “app”, “env”, and “node” in jobArgs. After calling the job’s Create method, the RM checks that all three are set in jobArgs (with any value, including nil). Like args:, this is strict but makes it possible to follow every arg through different sequences. It also makes it explicit which jobs set which args.retry: and retryWait: specify how many times the JR should retry the job if Run does not return proto.STATE_COMPLETE. The job is always ran once, so total runs is 1 + retry. retryWait is the wait time between tries. It is a time.Duration string like “3s” or “500ms”. If not specified, the default is no wait between tries.deps: is a list of node names that this node depends on. For nodes A and B, if B depends on A, the graph is A -&amp;gt; B. The JR runs B only after A completes successfully. A node can depend on many nodes, creating fan-out and fan-in points:      B -&amp;gt;    /       A -&amp;gt;        +-&amp;gt; E           /      C -&amp;gt;Node E has deps: [B,C]. Nodes B and C have deps: [A]. Node A has deps: [].deps: determines the order of nodes, not the order of node specs in the file. Every sequence must have a node with deps: [] (the first node in the sequence). Cycles are not allowed.Sequence NodeAll node specs begin with a node name: “notify-app-owners”, in this case. category: sequence makes this node a sequence node. type: specifies the sequence name: “notify-app-owners”. A node and sequence can have the same name. Whereas a job node runs a job, a sequence node imports another sequence.      notify-app-owners:        category: sequence        type: notify-app-owners        args:          - expected: appName            given: app          - expected: env            given: env        deps: [expand-cluster]        retry: 9        retryWait: 5000 # msWhen the RM encounters this sequence node, it looks for a sequence called “notify-app-owners”. (We would put that sequence in a file named notify-app-owners.yaml.) It replaces the sequence node with all the nodes in the target sequence. Since sequences can have required args, the sequence node must specify the args: to pass to the sequence (as if the sequence was a request). The same rules about args:, exepected:, and given: apply. The only difference is that the job args are passed to a sequence instead of a job.Sequences cannot set job args, so set: can be omitted.The same rules about deps: apply (described above). In this example, the “notify-app-owners” sequence is not called until the “expand-cluster” node is complete and successful. Likewise, if another node deps: [notify-app-owners], it is not called until the entire sequence is complete and successful. The sequence node, at this point in the spec, acts like a single node—it just happens to contain/run other nodes and sequences.retry: and retryWait: apply to sequences, too. If any job in the sequence fails, the entire sequence is retried from its beginning.Sequences of SequencesSequences “calling” sequences are how large requests are built. Like a job, a sequence is a unit of work—a bigger unit of work. The “notify-app-owners” sequence, for example, might have several jobs which detremine who the app owners are, what their notification preferences are, and then notify them accordingly. That is one unit of work: notifying app owners. It is also a reusable unit of work.Conditional Nodecategory: conditional makes this node a conditional node. if: specifies the job arg to use, and eq: operates like a switch cases on the if: job arg value.      restart-vttablet:        category: conditional        if: vitess        eq:          yes: restart-vttablet          default: noop        args:          - expected: node            given: name          - expected: host            given: physicalHost        deps: [bgp-peer-node]In the example above, if jobArgs[&quot;vitess&quot;] == &quot;yes&quot;, then sequence “restart-vttablet” is called. Else, the default is a special, built-in sequence called “noop” which does nothing. In the case that jobArgs[&quot;vitess&quot;] == &quot;yes&quot; and sequence “restart-vttablet” is called, the node acts exactly like a sequence node.All values and comparison are expected to be strings. The if: job arg must be set with a string value, and the values listed under eq: are string values, except “default” which is a special case.Conditional nodes can be used to switch between alternatives or, like the example above, do nothing in one part of a spec (but do everything else before and after).Sequence ExpansionSequence expansion is possible in sequence and conditional nodes with each::      decomm-nodes:        category: sequence        type: decomm-node        each:          - nodeHostname:node          - hosts:host        args: []          - expected: archiveData            given: archiveData        deps: []each: takes a list of job arg names and “expands” the sequence, “decomm-node”, in parallel for each job arg value. Expanded sequences are ran in parallel. There are currently no options to control this.The job args must be type []string of equal lengths. In this example, the job args could be:nodeHostname := []string{&quot;node1&quot;, &quot;node2&quot;}hsots := []string{&quot;host1&quot;, &quot;host2&quot;}The syntax is arg:alias (“arg as alias”) where each jobArg[alias] is initialized from the next value in arg. The target sequence should require alias.The args: are passed to each expanded sequence as-is, i.e. each “decomm-node” sequence receives jobArgs[archiveData].A conditional node with sequence expansion expands the sequence that matches if: and eq:.The same rules about deps: apply (described above).",
    "url": "http://localhost:4000/spincycle/v1.0/develop/requests.html",
    "relUrl": "/v1.0/develop/requests.html"
  },
  "19": {
    "id": "19",
    "title": "spinc (CLI)",
    "content": "spinc (CLI)spinc is the command line interface (CLI) for humans to operate Spin Cycle. spinc uses the Request Manager client, so anything spinc does can be done through the Request Manager API. spinc just makes it a little easier for humans, rather than querying the API directly.addrspinc needs the Request Manager address specified by --addr, or SPINC_ADDR environment variable, or addr: &amp;lt;URL&amp;gt; in /etc/spinc/spinc.yaml or ~/.spinc.yaml. Setting addr in one of the config YAML files is probably easiest. If many RM are deployed, this should be the URL of the load balancer.Once addr is set, run spinc (no arguments) to list available requests:$ spincRequest Manager address: https://mycorp.local:32308Requests:  checksum-mysql-metacluster  provision-mysql-cluster  provision-redis-cluster  start-host  stop-host  test  update-mysql-ibpspinc help  &amp;lt;request&amp;gt;spinc start &amp;lt;request&amp;gt;This queries the Request Manager to obtain the list of requests.CommandsThe spinc commands are:            Command      Purpose                  help [command]      Print general help and command-specific help              info &amp;lt;ID&amp;gt;      Print complete request information              log &amp;lt;ID&amp;gt;      Print job log (hint: pipe output to less)              ps [ID]      Show running requests and jobs. Request ID is optional.              running      Exit 0 if request is running or pending, else exit 1              start &amp;lt;ID&amp;gt;      Start new request              status &amp;lt;ID&amp;gt;      Print request status and basic information              stop &amp;lt;ID&amp;gt;      Stop request      Run spinc start &amp;lt;request&amp;gt; to start a request by name. It will prompt you for request arguments (args) in the order listed in the request spec, required then optional args.Use spinc status &amp;lt;request ID&amp;gt; and spinc log &amp;lt;request ID&amp;gt; to check the status and results of a request.spinc ps shows all running requests/jobs, analogous to Unix ps. You can specify an optional request ID to show only its running jobs.Environment Variables            Option      Environment Variable                  –addr      SPINC_ADDR              –config      SPINC_CONFIG              –debug      SPINC_DEBUG              –env      SPINC_ENV              –timeout      SPINC_TIMEOUT      Options not listed do not have an environment variable.",
    "url": "http://localhost:4000/spincycle/v1.0/operate/spinc.html",
    "relUrl": "/v1.0/operate/spinc.html"
  },
  "20": {
    "id": "20",
    "title": "Support",
    "content": "SupportFor bugs and general issues, please create a new GitHub issue.If submitting code changes, please also see the contributing guide.",
    "url": "http://localhost:4000/spincycle/v1.0/learn-more/support.html",
    "relUrl": "/v1.0/learn-more/support.html"
  }
}
